{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "\n",
    "import nilmtk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import os, ast\n",
    "from sys import argv\n",
    "from time import time\n",
    "import nilmtk\n",
    "import nilmtk_contrib\n",
    "from nilmtk.api import API\n",
    "from nilmtk.disaggregate import Mean, FHMMExact, CO, Hart85\n",
    "from nilmtk_contrib.disaggregate import AFHMM, AFHMM_SAC, DSC, DAE, Seq2Point, Seq2Seq, RNN, WindowGRU\n",
    "nilmtk.Appliance.allow_synonyms=False\n",
    "import time\n",
    "import scipy.stats \n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import seaborn as sns\n",
    "import math\n",
    "from math import pi\n",
    "import pickle\n",
    "\n",
    "#load REFIT dataset\n",
    "dataset = nilmtk.DataSet('REFIT.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUILDING = 19\n",
    "\n",
    "#sample rate\n",
    "SAMPLE_RATE = '60s'\n",
    "\n",
    "#experiment window\n",
    "START = \"2014-06-21\"\n",
    "\n",
    "END = \"2015-06-20\"\n",
    "\n",
    "dataset.set_window(START, END)\n",
    "\n",
    "# elec[1] refers to the mains\n",
    "dataset_mains = next(dataset.buildings[BUILDING].elec[1].load())['power'].resample(SAMPLE_RATE).fillna(\"pad\").values.tolist()\n",
    "dataset_mains.remove(dataset_mains[0]) \n",
    "\n",
    "#function that computes total noise in the building aggregate\n",
    "def get_noise(mains):\n",
    "    noise_seq2 = mains\n",
    "    for j in range(1, len(dataset.buildings[BUILDING].elec.appliances)):\n",
    "        if dataset.buildings[BUILDING].elec[j+1].appliances[0].type['type'] != 'unknown':\n",
    "            dataset_aux = next(dataset.buildings[BUILDING].elec[j+1].load())['power'].resample(SAMPLE_RATE).fillna(\"pad\").values.tolist()                \n",
    "            dataset_aux.remove(dataset_aux[0])\n",
    "            \n",
    "            if len(mains) != len(dataset_aux):\n",
    "                print(\"length of mains observed sequence differs from that of the selected appliance\")\n",
    "            else:\n",
    "\n",
    "                for i in range(0, len(mains)): \n",
    "                    noise_seq2[i][0] = noise_seq2[i][0] - dataset_aux[i][0]\n",
    "            \n",
    "    return noise_seq2\n",
    " \n",
    "noise_total = get_noise(dataset_mains)\n",
    "noise_total = [item for sublist in noise_total for item in sublist]\n",
    "dataset_mains=next(dataset.buildings[BUILDING].elec[1].load())['power'].resample(SAMPLE_RATE).fillna(\"pad\").values.tolist()\n",
    "dataset_mains.remove(dataset_mains[0])\n",
    "\n",
    "#get the proportion of noise in the building aggregate\n",
    "def get_noise_prop_agg(mains, noise):\n",
    "    noise_t = 0\n",
    "    agg_total = 0    \n",
    "    for i in range(0, len(noise)):\n",
    "        noise_t += abs(noise[i])\n",
    "        agg_total += abs(mains[i][0])\n",
    "    return agg_total/noise_t\n",
    "\n",
    "\n",
    "#get the appliance to noise ratio\n",
    "def get_noise_prop_app(app, noise):\n",
    "    noise_t = 0\n",
    "    app_total = 0\n",
    "    for i in range(0, len(noise)):\n",
    "        app_total += abs(app[i][0])\n",
    "        noise_t += abs(noise[i])\n",
    "    return app_total/noise_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of dictionaries\n",
    "\n",
    "#for saving the total noise for each appliance across the houses\n",
    "noise_wm_60 = {}\n",
    "noise_dw_60 = {}\n",
    "noise_mw_60 = {}\n",
    "noise_kt_60 = {}\n",
    "\n",
    "#proportion of noise in the aggregate, and the appliance-to-noise ratios for each appliance\n",
    "ratios_60 = {} #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appliances considered\n",
    "load1 = \"washing machine\"\n",
    "\n",
    "load2 = \"dish washer\"\n",
    "\n",
    "load3 = \"microwave\"\n",
    "\n",
    "load4 = \"kettle\"\n",
    "\n",
    "#get power values sampled at 1/60hz\n",
    "dataset_wm=next(dataset.buildings[BUILDING].elec[load1].load())['power'].resample(SAMPLE_RATE).fillna(\"pad\").values.tolist()\n",
    "dataset_wm.remove(dataset_wm[0])\n",
    "\n",
    "dataset_dw=next(dataset.buildings[BUILDING].elec[load2].load())['power'].resample(SAMPLE_RATE).fillna(\"pad\").values.tolist()\n",
    "dataset_dw.remove(dataset_dw[0])\n",
    "\n",
    "dataset_mw=next(dataset.buildings[BUILDING].elec[load3].load())['power'].resample(SAMPLE_RATE).fillna(\"pad\").values.tolist()\n",
    "dataset_mw.remove(dataset_mw[0])\n",
    "\n",
    "dataset_kt=next(dataset.buildings[BUILDING].elec[load4].load())['power'].resample(SAMPLE_RATE).fillna(\"pad\").values.tolist()\n",
    "dataset_kt.remove(dataset_kt[0])\n",
    "\n",
    "#The 20 REFIT houses ID ranges from 1 to 21, except 14, but they are indexed from 1 to 20 \n",
    "#therefore for houses indexed above 14, BUILDING ID= index+1  \n",
    "if BUILDING >= 14:\n",
    "    BUILDING = BUILDING+1\n",
    "    noise_wm_60[str(BUILDING)] = noise_total\n",
    "else:\n",
    "    noise_wm_60[str(BUILDING)] = noise_total\n",
    "    \n",
    "#then compute for the other appliances    \n",
    "\n",
    "\n",
    "ratios_60[str(BUILDING)] = [get_noise_prop_agg(dataset_mains, noise_total), get_noise_prop_app(dataset_wm, noise_total),  \n",
    "                             get_noise_prop_app(dataset_dw, noise_total), get_noise_prop_app(dataset_mw, noise_total)\n",
    "                            get_noise_prop_app(dataset_kt, noise_total)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as pickle \n",
    "dbfile = open('ratios_60', 'ab')\n",
    "b=pickle.dump(ratios_60, dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pickle\n",
    "ratios_60_pickle = open('ratios_60', 'rb')     \n",
    "ratios_60_pickle = pickle.load(ratios_60_pickle)\n",
    "\n",
    "ratios_60_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get number of activations of all appliances in the building\n",
    "#only the activation times larger than 1 minute are selected for calculating this number \n",
    "\n",
    "def get_total_activations(BUILDING, min_on):\n",
    "    res = 0\n",
    "    for j in range(1, len(dataset.buildings[BUILDING].elec.appliances)):\n",
    "        if dataset.buildings[BUILDING].elec[j+1].appliances[0].type['type'] != 'unknown':\n",
    "            res += len(dataset.buildings[BUILDING].elec[j+1].get_activations(min_on_duration = min_on))  \n",
    "        \n",
    "    return res    \n",
    "\n",
    "# get number of activations of an appliance \n",
    "def get_load_activations (BUILDING, load, min_on):\n",
    "    res = 0\n",
    "    if dataset.buildings[BUILDING].elec[load].appliances[0].type['type'] != 'unknown':\n",
    "        res = len(dataset.buildings[BUILDING].elec[load].get_activations(min_on_duration = min_on))      \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Houses = ['2' , '3' , '5' , '6' , '9' , '11' , '13' , '20'] #11 houses\n",
    "#these houses are considered because they include at least one of each appliance: washing machine, dish washer, microwave \n",
    "#and kettle\n",
    "\n",
    "LOAD = \"washing machine\"\n",
    "res = []\n",
    "for i in Houses:\n",
    "    if int(i) < 14:\n",
    "        res.append( (get_load_activations(int(i), LOAD, SAMPLE_RATE)/get_total_activations(int(i), SAMPLE_RATE))*ratios_60_pickle[i][0] )\n",
    "    else: \n",
    "        res.append( (get_load_activations(int(i)-1, LOAD, SAMPLE_RATE)/get_total_activations(int(i)-1, SAMPLE_RATE))*ratios_60_pickle[i][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute signal-to-noise ratio\n",
    "def SNR(data):\n",
    "    res = []\n",
    "    for i in Houses:\n",
    "        res.append( 10*math.log10(data[i][0]) )\n",
    "    return res\n",
    "\n",
    "SNR(ratios_60_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute noise-to-aggregate ratio\n",
    "def NAR(data):\n",
    "    res = []\n",
    "    for i in Houses:\n",
    "        res.append( 1/data[i][0] )\n",
    "    return res\n",
    "\n",
    "NAR(ratios_60_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#illustration figure showed in the paper\n",
    "\n",
    "labels = [\"\", \"2\", \"3\",  \"5\", \"6\", \"9\", \"11\", \"13\", \"20\", \"9\", \"\", \"11\", \"\", \"13\", \"\", \"20\", \"\" ]\n",
    "anr = [0.06, 0.05, 0.04, 0.06, 0.07, 0.16, 0.03, 0.06]\n",
    "aka = [0.221, 0.102, 0.102, 0.137, 0.145, 0.230, 0.174, 0.088]\n",
    "wanr = [0.014, 0.005, 0.004, 0.009, 0.010, 0.038, 0.005, 0.005]\n",
    "\n",
    "x = np.arange(8) \n",
    "width = 0.2\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, anr, width, label='ANR')\n",
    "rects2 = ax.bar(x, aka, width, label='A_k/A')\n",
    "rects3 = ax.bar(x + width, wanr, width, label='WANR')\n",
    "\n",
    "ax.set_ylabel('Scores', fontsize = 16)\n",
    "ax.set_xlabel('Houses', fontsize = 16)\n",
    "ax.set_title('ANR, A_k/A and WANR scores across the selected houses', fontsize = 16)\n",
    "ax.set_xticks(x, labels)\n",
    "ax.set_yticks(np.arange(0, 0.27, 0.03))\n",
    "ax.set_yticklabels(np.arange(0, 0.27, 0.03), fontsize = 16)\n",
    "ax.set_xticklabels(labels, fontsize = 16)\n",
    "ax.legend(fontsize = 16)\n",
    "\n",
    "ax.grid(linestyle = '--', linewidth = 1)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplots of power consumption when the appliance is turned on\n",
    "\n",
    "load = \"microwave\"\n",
    "\n",
    "Houses = ['2', '3', '5', '6', '9', '10', '11', '13', '15', '18', '20']\n",
    "\n",
    "KETTLE_dict = {}\n",
    "for i in Houses:\n",
    "    if int(i)<14:\n",
    "        KETTLE = next(dataset.buildings[int(i)].elec[load].load(sample_period = 60)).values\n",
    "    else:     \n",
    "        KETTLE = next(dataset.buildings[int(i)-1].elec[load].load(sample_period = 60)).values    \n",
    "    KETTLE = [KETTLE[j][0] for j in range(KETTLE.shape[0]) if KETTLE[j][0]>5]\n",
    "    KETTLE_dict[i] = KETTLE\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "labels, data = KETTLE_dict.keys(), KETTLE_dict.values()\n",
    "plt.boxplot(data)\n",
    "plt.xticks(range(1, len(labels) + 1), labels, fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.grid(linestyle = '--', linewidth = 1)\n",
    "plt.title(\"Distribution of \"+str(load)+\" power consumption at 1/60 Hz when turned ON\", fontsize = 16)\n",
    "plt.xlabel(\"Houses\", fontsize = 16)\n",
    "plt.ylabel(\"Active Power (W)\", fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house=2\n",
    "dataset_wm=next(dataset.buildings[house].elec[\"washing machine\"].load())['2014-06-21' : '2015-06-20']['power']\n",
    "\n",
    "X = dataset_wm.values\n",
    "tscv = TimeSeriesSplit(n_splits = 2)\n",
    "print(tscv)\n",
    "train_index_num = []\n",
    "test_index_num = [] \n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index, :], X[test_index, :]\n",
    "    train_index_num.append(train_index)\n",
    "    test_index_num.append(test_index)\n",
    "    \n",
    "train_inic = dataset_wm[0: train_index_num[1][-1]].index.strftime('%Y-%m-%d')[0]\n",
    "train_fim = dataset_wm[0: train_index_num[1][-1]].index.strftime('%Y-%m-%d')[-1]\n",
    "test_inic = dataset_wm[0: test_index_num[1][-1]].index.strftime('%Y-%m-%d')[0]\n",
    "test_fim = dataset_wm[0: test_index_num[1][-1]].index.strftime('%Y-%m-%d')[-1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_interval = 60\n",
    "load = 'washing machine'\n",
    "\n",
    "BUILDING = 5\n",
    "\n",
    "train_inicio=train_inic\n",
    "train_final=train_fim\n",
    "test_inicio=test_inic\n",
    "test_final= test_fim\n",
    "\n",
    "experiment = {\n",
    "    'power': { 'mains': ['active'], 'appliance': ['active'] },\n",
    "    'sample_rate': sampling_interval,\n",
    "    'appliances': [load],\n",
    "    'methods': { \n",
    "        #'FHMMExact': FHMMExact({}) },\n",
    "        #'CO': CO({})},\n",
    "        #'DSC':DSC({'learning_rate':1e-11, 'iterations':50}) },\n",
    "        #'RNN': RNN({'n_epochs': 50, 'batch_size': 1024})  },\n",
    "        'DAE': DAE({'n_epochs': 50, 'batch_size': 1024}),\n",
    "        'Seq2Point': Seq2Point({'n_epochs': epochs, 'batch_size': 128}),\n",
    "        'Seq2Seq': Seq2Seq({'n_epochs': epochs, 'batch_size': 1024})}\n",
    "        #'WindowGRU':WindowGRU({'n_epochs':epochs,'batch_size':1024}),\n",
    "    'train': {\n",
    "        'datasets': {\n",
    "            'REFIT': {\n",
    "                'path': 'REFIT.h5'.format(),\n",
    "                'buildings': {\n",
    "                    BUILDING: {\n",
    "                        'start_time': train_inicio,\n",
    "                        'end_time': train_final\n",
    "                }\n",
    "                }\n",
    "        }\n",
    "    }\n",
    "},\n",
    "    'test': {\n",
    "        'datasets': {\n",
    "            'REFIT': {\n",
    "                'path': 'REFIT.h5'.format(),\n",
    "                'buildings': {\n",
    "                     BUILDING: {\n",
    "                         'start_time': test_inicio,\n",
    "                         'end_time': test_final\n",
    "                        } \n",
    "                    }\n",
    "            }\n",
    "    },   \n",
    "    'metrics': ['mae'] #disaggregation performance with MAE\n",
    "    }\n",
    "} \n",
    "    \n",
    "# Conduct experiment in NILMTK\n",
    "api_results = API(experiment) #results are saved\n",
    "exit()\n",
    "    \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "import os, ast\n",
    "from time import time\n",
    "import nilmtk\n",
    "import nilmtk_contrib\n",
    "from nilmtk.api import API\n",
    "from nilmtk.disaggregate import Mean, FHMMExact, CO, Hart85\n",
    "from nilmtk_contrib.disaggregate import AFHMM, AFHMM_SAC, DSC, DAE, Seq2Point, Seq2Seq, RNN, WindowGRU\n",
    "nilmtk.Appliance.allow_synonyms=False\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "dataset = nilmtk.DataSet('REFIT.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate normalized AE\n",
    "\n",
    "# MAE*N = AE\n",
    "# then, normalized AE = AE/sum(App)\n",
    "\n",
    "App = next(dataset.buildings[5].elec[load].load(sample_period = 60))['power'].values.tolist()\n",
    "\n",
    "inic_test_set = len(App)*0.33\n",
    "App = [item for sublist in App for item in sublist]\n",
    "\n",
    "api_results[0]/sum(App)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anr, wanr, mae and normalized AE obtained from the experimental evaluation \n",
    "\n",
    "\n",
    "wm_anr = [0.05, 0.07, 0.07, 0.02, 0.04, 0.01, 0.05, 0.03] #for the wm across 11 houses\n",
    "wm_wanr = [0.001, 0.002, 0.002, 0, 0.001, 0, 0.004, 0]\n",
    "\n",
    "nar = [0.71, 0.6, 0.62, 0.64, 0.66, 0.79, 0.70, 0.58] \n",
    "\n",
    "wm_normAE = [0.89, 0.64, 1.16, 0.51, 0.77, 1.28, 0.57, 0.71] \n",
    "wm_mae = [15.62, 19.98, 39.37, 3.07, 11.63, 4.85, 10.21, 4.85]\n",
    "\n",
    "dw_anr = [0.17, 0.13, 0.11, 0.03, 0.12, 0.01, 0.05, 0.03]\n",
    "dw_wanr = [0.006, 0.002, 0.002, 0, 0.002, 0, 0.002, 0]\n",
    "\n",
    "dw_normAE = [0.69, 0.48, 0.42, 0.39, 0.36, 1.46, 2.51, 0.53]\n",
    "dw_mae = [45.07, 24.07, 23.20, 3.61, 16.82, 5.72, 66.44, 4.27]\n",
    "\n",
    "mw_anr = [0.01, 0.01, 0.05, 0.02, 0, 0.01, 0.12, 0.07]\n",
    "mw_wanr = [ 0, 0, 0.003, 0.001, 0, 0, 0.064, 0.003]\n",
    "\n",
    "mw_normAE = [0.76, 1.28, 0.63, 0.53, 1.36, 0.89, 0.31, 0.08]\n",
    "mw_mae = [2.95, 3.89, 16.39, 3.74, 1.89, 2.82, 18.56, 2.07]\n",
    "\n",
    "kt_anr = [0.06, 0.05, 0.04, 0.06, 0.07, 0.16, 0.03, 0.16]\n",
    "kt_wanr = [0.013, 0.005, 0.004, 0.008, 0.009, 0.036, 0.005, 0.005]\n",
    "\n",
    "kt_normAE = [0.24, 0.94, 0.44, 0.26, 0.31, 0.90, 0.87, 0.10]\n",
    "kt_mae = [4.89, 18.27, 9.67, 4.75, 7.39, 143.46, 7.33, 2.48]\n",
    "\n",
    "\n",
    "#compute pearson and spearman correlation coefficients\n",
    "scipy.stats.pearsonr(kt_anr, kt_normAE)\n",
    "scipy.stats.spearmanr(kt_anr, kt_normAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spider chart at the appliance-level\n",
    "\n",
    "df = pd.DataFrame({\n",
    "'Correlation': ['ANR, norm AE','WANR, norm AE','ANR, MAE','WANR, MAE'],\n",
    "'WM': [0.02, 0.14, 0.90, 0.72],\n",
    " 'DW': [0.21, 0.05, 0.66, 0.85], \n",
    "   'MW': [0.93, 0.56, 0.56, 0.52],\n",
    "    'KT': [0.37, 0.07,0.12, 0.12]\n",
    "})\n",
    "     \n",
    "# ------- PART 1: Define a function that do a plot for one line of the dataset!    \n",
    "def make_spider( row, title, color):\n",
    "\n",
    "    # number of variable\n",
    "    categories=list(df)[1:]\n",
    "    N = len(categories)\n",
    "\n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    # Initialise the spider plot\n",
    "    ax = plt.subplot(2,2,row+1, polar=True, )\n",
    "\n",
    "    # If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], categories, color='black', size=20)\n",
    "\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0.25,0.5,0.75], [\"0.25\",\"0.5\",\"0.75\"], color=\"black\", size=20)\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    # Ind1\n",
    "    values=df.loc[row].drop('Correlation').values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, color=color, linewidth=2, linestyle='solid')\n",
    "    ax.fill(angles, values, color=color, alpha=0.4)\n",
    "\n",
    "    # Add a title\n",
    "    plt.title(title, size=20, y=1.1)\n",
    "\n",
    "    \n",
    "# ------- PART 2: Apply the function to all individuals\n",
    "# initialize the figure\n",
    "my_dpi=70\n",
    "plt.figure(figsize=(1200/my_dpi, 1200/my_dpi), dpi=my_dpi)\n",
    " \n",
    "# Create a color palette:\n",
    "my_palette = plt.cm.get_cmap(\"Set2\", len(df.index))\n",
    " \n",
    "# Loop to plot\n",
    "for row in range(0, len(df.index)):\n",
    "    #row = 3\n",
    "    make_spider(row, title='Correlation '+df['Correlation'][row], color=my_palette(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spider chart at the house-level\n",
    "\n",
    "df = pd.DataFrame({\n",
    "'Correlation': ['ANR, norm AE','WANR, norm AE','ANR, MAE','WANR, MAE'],\n",
    "'2': [0.60, 0.8, 0.8, 0.4],\n",
    " '3': [1, 0.32, 1, 0.32], \n",
    "   '5': [0.2, 0.11, 0.8, 0.95],\n",
    "    '6': [0.95, 0.32, 0.63, 0.95], \n",
    "    '9': [0.8, 1, 0.8, 0.4],\n",
    "    '11': [0.25, 0.26, 0.77, 0.77],\n",
    "    '13': [0.63, 0.80, 0.63, 0.4], \n",
    "    '20': [1, 0.74, 1, 0.74]\n",
    "})\n",
    " \n",
    "# ------- PART 1: Define a function that do a plot for one line of the dataset!\n",
    " \n",
    "def make_spider( row, title, color):\n",
    "\n",
    "    # number of variable\n",
    "    categories=list(df)[1:]\n",
    "    N = len(categories)\n",
    "\n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    # Initialise the spider plot\n",
    "    ax = plt.subplot(2,2,row+1, polar=True, )\n",
    "\n",
    "    # If you want the first axis to be on top:\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], categories, color='black', size=20)\n",
    "\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([0.25,0.5,0.75], [\"0.25\",\"0.5\",\"0.75\"], color=\"black\", size=20)\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    # Ind1\n",
    "    values=df.loc[row].drop('Correlation').values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, color=color, linewidth=2, linestyle='solid')\n",
    "    ax.fill(angles, values, color=color, alpha=0.4)\n",
    "\n",
    "    # Add a title\n",
    "    plt.title(title, size=20, y=1.1)\n",
    "\n",
    "    \n",
    "# ------- PART 2: Apply the function to all individuals\n",
    "# initialize the figure\n",
    "my_dpi=70\n",
    "plt.figure(figsize=(1200/my_dpi, 1200/my_dpi), dpi=my_dpi)\n",
    " \n",
    "# Create a color palette:\n",
    "my_palette = plt.cm.get_cmap(\"Set2\", len(df.index))\n",
    " \n",
    "# Loop to plot\n",
    "\n",
    "for row in range(0, len(df.index)):\n",
    "    make_spider( row=row, title='Correlation '+df['Correlation'][row], color=my_palette(row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
